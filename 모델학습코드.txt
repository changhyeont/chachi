#!/usr/bin/env python
# coding: utf-8


# In[1]:


import sagemaker
from sagemaker import get_execution_role
from sagemaker.sklearn import SKLearn


# In[2]:


sagemaker_session = sagemaker.Session()
role = get_execution_role()  # SageMaker 역할 자동 추출


# In[3]:


bucket_name = ""  # 버킷 이름 수정
input_data_path = f""  # 입력 데이터 경로 수정
output_path = f""  # 출력 경로 (모델 파일 저장)


# In[4]:


training_script_path = "train_script.py"  # 훈련 스크립트 파일명

# 훈련 스크립트 작성
with open(training_script_path, "w") as f:
    f.write("""
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
import joblib
import os
import json
import numpy as np
import boto3
from io import StringIO

def load_data_from_s3(bucket, prefix):
    s3 = boto3.client('s3')
    data = []
    labels = []
    
    # S3 버킷의 객체 리스트 가져오기
    response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
    
    for obj in response.get('Contents', []):
        if obj['Key'].endswith('.json'):
            # JSON 파일 읽기
            file_obj = s3.get_object(Bucket=bucket, Key=obj['Key'])
            file_content = file_obj['Body'].read().decode('utf-8')
            route_data = json.loads(file_content)
            
            # 시작점 추가
            start_point = route_data['route']['start_point']
            data.append([start_point['latitude'], start_point['longitude']])
            labels.append(0)
            
            # 경유점 추가
            for point in route_data['route']['waypoints']:
                data.append([point['latitude'], point['longitude']])
                labels.append(0)
            
            # 종료점 추가
            end_point = route_data['route']['end_point']
            data.append([end_point['latitude'], end_point['longitude']])
            labels.append(0)
            
    return np.array(data), np.array(labels)

def model_fn(model_dir):
    model_path = os.path.join(model_dir, "model.joblib")
    print(f"Loading model from {model_path}")
    model = joblib.load(model_path)
    return model

def input_fn(request_body, request_content_type):
    print(f"Processing input data. Content type: {request_content_type}")
    if request_content_type == "application/json":
        data = json.loads(request_body)
        # 문자열을 float로 변환
        return np.array([[float(data["latitude"]), float(data["longitude"])]])
    else:
        raise ValueError(f"Unsupported content type: {request_content_type}")

def predict_fn(input_data, model):
    print(f"Performing prediction on input data: {input_data}")
    # 입력 데이터가 float 타입인지 확인
    input_data = input_data.astype(float)
    distances, indices = model.kneighbors(input_data)
    
    # 가장 가까운 이웃까지의 거리가 임계값보다 크면 비정상으로 판단
    threshold = 0.001  # 임계값 설정 (조정 가능)
    is_normal = distances[0][0] <= threshold
    
    return {
        "prediction": "정상" if is_normal else "비정상",
        "distance": float(distances[0][0])
    }    

def main():
    print("Starting training...")
    
    # S3 버킷과 경로 설정
    bucket = "ai-22029398"
    prefix = "route_test"
    
    # 데이터 로드
    print("Loading data from S3...")
    X, y = load_data_from_s3(bucket, prefix)
    print(f"Loaded {len(X)} data points")
    
    # KNN 모델 학습
    print("Training KNN model...")
    knn = KNeighborsClassifier(n_neighbors=3)
    knn.fit(X, y)
    
    # 모델 저장
    model_dir = os.environ.get("SM_MODEL_DIR", "/opt/ml/model")
    model_path = os.path.join(model_dir, "model.joblib")
    joblib.dump(knn, model_path)
    print(f"Model saved to {model_path}")

if __name__ == "__main__":
    main()
""")


# In[5]:


sklearn_estimator = SKLearn(
    entry_point=training_script_path,
    framework_version="1.2-1",
    instance_type="ml.m5.large",
    instance_count=1,
    role=role,
    sagemaker_session=sagemaker_session,
    base_job_name="route-anomaly-detection",
    output_path=output_path,
)

# 훈련 작업 시작
sklearn_estimator.fit({"train": input_data_path})

# In[6]:


from sagemaker.sklearn import SKLearnModel
from urllib.parse import urlparse
import os

# 훈련 결과에서 모델 경로 추출
model_artifact = sklearn_estimator.model_data  # S3에 저장된 모델 아티팩트 경로
print(f"Model artifact saved at: {model_artifact}")

# source_dir 경로 수정 (s3://<bucket>/<base_job_name>/source/sourcedir.tar.gz)
parsed_url = urlparse(model_artifact)
bucket = parsed_url.netloc
path_parts = parsed_url.path.split("/")  # 경로를 '/' 기준으로 나눔

# 필요한 경로 추출
base_path = "/".join(path_parts[2:3])
source_dir = f"s3://{bucket}/{base_path}/source/sourcedir.tar.gz"

print(f"Source directory inferred as: {source_dir}")


# In[7]:


# SageMaker Model 생성
sklearn_model = SKLearnModel(
    model_data=model_artifact,
    role=role,
    framework_version="1.2-1",
    sagemaker_session=sagemaker_session,
    entry_point="train_script.py",  # 훈련에 사용된 스크립트
    source_dir=source_dir,  # 추론 스크립트 경로
    env={
        "SAGEMAKER_PROGRAM": "train_script.py",  # 실행할 스크립트
        "SAGEMAKER_SUBMIT_DIRECTORY": source_dir  # 소스 디렉토리
    }
)

# 엔드포인트 생성
endpoint_name = "route-anomaly-detection-endpoint"  # 엔드포인트 이름 변경
sklearn_model.deploy(
    initial_instance_count=1,
    instance_type="ml.m5.large",
    endpoint_name=endpoint_name,
)

print(f"Endpoint {endpoint_name} created successfully!")


